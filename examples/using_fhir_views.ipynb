{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to using FHIR Data Pipes and FHIR Views\n",
    "In this example we will show how to use FHIR Views with data generated using the FHIR Data Pipes library"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prerequisites:\n",
    "\n",
    "**Note**: All commands need to be run from the root directory of the fhir-data-pipes repo\n",
    "\n",
    "1. Bring up a Hive ThriftServer:\n",
    "    ```\n",
    "    docker-compose  -f ./docker/compose-controller-spark-sql-single.yaml up --build  --force-recreate -d\n",
    "    ```\n",
    "\n",
    "2. Bring up a HAPI FHIR server:\n",
    "    ```\n",
    "    docker-compose  -f ./docker/hapi-compose.yml up --force-recreate -d\n",
    "    ```\n",
    "\n",
    "3. Load data into the HAPI FHIR server:\n",
    "    ```\n",
    "    python3 ./synthea-hiv/uploader/main.py HAPI http://localhost:8091/fhir --input_dir ./synthea-hiv/sample_data\n",
    "    ```\n",
    "\n",
    "4. In the FHIR Pipelines Control Panel page, http://localhost:8090, click on “Run Full” button to export the data to SQL-on-FHIR format. The exported parquet files will be stored under the `docker/dwh` directory\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install the FHIR Views library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: google-fhir-views[r4,spark] in /usr/local/google/home/omarismail/.local/lib/python3.10/site-packages (0.9.2)\n",
      "\u001b[33mWARNING: google-fhir-views 0.9.2 does not provide the extra 'spark'\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: absl-py~=1.1 in /usr/local/google/home/omarismail/.local/lib/python3.10/site-packages (from google-fhir-views[r4,spark]) (1.4.0)\n",
      "Requirement already satisfied: protobuf~=3.19 in /usr/local/google/home/omarismail/.local/lib/python3.10/site-packages (from google-fhir-views[r4,spark]) (3.20.2)\n",
      "Requirement already satisfied: pandas~=1.1 in /usr/local/google/home/omarismail/.local/lib/python3.10/site-packages (from google-fhir-views[r4,spark]) (1.5.0)\n",
      "Requirement already satisfied: google-fhir-core~=0.9.2 in /usr/local/google/home/omarismail/.local/lib/python3.10/site-packages (from google-fhir-views[r4,spark]) (0.9.2)\n",
      "Requirement already satisfied: python-dateutil~=2.8 in /usr/local/google/home/omarismail/.local/lib/python3.10/site-packages (from google-fhir-views[r4,spark]) (2.8.2)\n",
      "Requirement already satisfied: requests~=2.27 in /usr/lib/python3/dist-packages (from google-fhir-views[r4,spark]) (2.28.1)\n",
      "Requirement already satisfied: requests-mock~=1.9 in /usr/local/google/home/omarismail/.local/lib/python3.10/site-packages (from google-fhir-views[r4,spark]) (1.10.0)\n",
      "Requirement already satisfied: immutabledict~=2.2 in /usr/local/google/home/omarismail/.local/lib/python3.10/site-packages (from google-fhir-views[r4,spark]) (2.2.1)\n",
      "Requirement already satisfied: google-fhir-r4~=0.9.2 in /usr/local/google/home/omarismail/.local/lib/python3.10/site-packages (from google-fhir-views[r4,spark]) (0.9.2)\n",
      "Requirement already satisfied: stringcase==1.2.0 in /usr/local/google/home/omarismail/.local/lib/python3.10/site-packages (from google-fhir-core~=0.9.2->google-fhir-views[r4,spark]) (1.2.0)\n",
      "Requirement already satisfied: antlr4-python3-runtime~=4.9.3 in /usr/local/google/home/omarismail/.local/lib/python3.10/site-packages (from google-fhir-core~=0.9.2->google-fhir-views[r4,spark]) (4.9.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /usr/lib/python3/dist-packages (from pandas~=1.1->google-fhir-views[r4,spark]) (1.24.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas~=1.1->google-fhir-views[r4,spark]) (2022.7.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil~=2.8->google-fhir-views[r4,spark]) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install google-fhir-views[r4,spark]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "from sqlalchemy import dialects\n",
    "from sqlalchemy import engine\n",
    "\n",
    "from google.fhir.views import r4\n",
    "from google.fhir.views import spark_runner\n",
    "\n",
    "# The Spark dataset containing FHIR data. This may be read-only to the user.\n",
    "fhir_dataset = \"default\"\n",
    "\n",
    "# The Spark dataset where we will create views, value sets, and other derived tables\n",
    "# as needed. This must be writeable by the user. This will use the default project\n",
    "# where this notebook is running.\n",
    "analysis_dataset = \"statin_analysis_example\"\n",
    "\n",
    "dialects.registry.register(\"hive\", \"pyhive.sqlalchemy_hive\", \"HiveDialect\")\n",
    "\n",
    "# The endpoint of the Hive ThriftServer to connect to\n",
    "query_engine = engine.create_engine(\"hive://localhost:10001/default\")\n",
    "\n",
    "# Create a runner to execute the views over Spark.\n",
    "runner = spark_runner.SparkRunner(\n",
    "    query_engine=query_engine,\n",
    "    fhir_dataset=fhir_dataset,\n",
    "    view_dataset=analysis_dataset,\n",
    "    snake_case_resource_tables=True,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below loads the parquet files we've downloaded into our Spark ThriftServer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_directory_path = \"/dwh/controller_*\"\n",
    "with query_engine.connect() as curs:\n",
    "    curs.execute(f\"DROP TABLE IF EXISTS {fhir_dataset}.encounter;\")\n",
    "    curs.execute(f\"DROP TABLE IF EXISTS {fhir_dataset}.observation;\")\n",
    "    curs.execute(f\"DROP TABLE IF EXISTS {fhir_dataset}.patient;\")\n",
    "    curs.execute(\n",
    "        f\"CREATE TABLE IF NOT EXISTS {fhir_dataset}.encounter USING\"\n",
    "        f\" PARQUET LOCATION '{destination_directory_path}/Encounter/*.parquet';\"\n",
    "    )\n",
    "    curs.execute(\n",
    "        f\"CREATE TABLE IF NOT EXISTS {fhir_dataset}.observation USING PARQUET\"\n",
    "        f\" LOCATION '{destination_directory_path}/Observation/*.parquet';\"\n",
    "    )\n",
    "    curs.execute(\n",
    "        f\"CREATE TABLE IF NOT EXISTS {fhir_dataset}.patient USING PARQUET\"\n",
    "        f\" LOCATION '{destination_directory_path}/Patient/*.parquet';\"\n",
    "    )\n",
    "\n",
    "    curs.execute(f\"DROP DATABASE IF EXISTS {analysis_dataset} CASCADE;\")\n",
    "    curs.execute(f\"CREATE DATABASE IF NOT EXISTS {analysis_dataset};\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore the data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting a general feeling for the data is an important first step in any analysis. So let's create some views of FHIR resources and take a look at common fields.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load views based on the base FHIR R4 profile definitions.\n",
    "views = r4.base_r4()\n",
    "\n",
    "# Create shorthand names for resources we will work with.\n",
    "conds = views.view_of(\"Condition\")\n",
    "meds = views.view_of(\"MedicationRequest\")\n",
    "obs = views.view_of(\"Observation\")\n",
    "pats = views.view_of(\"Patient\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting a general feeling for the data is an important first step in any analysis. So let's create some views of FHIR resources and take a look at common fields. Note that the results of this notebook are very similar to the BigQuery notebook. Being able to define views independent of the runner is one of the main advantages of using FHIR Views."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>code_display</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[\"survey\"]</td>\n",
       "      <td>[\"CURRENT ANTIRETROVIRAL DRUGS USED FOR TREATM...</td>\n",
       "      <td>final</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[\"survey\"]</td>\n",
       "      <td>[\"LOINC Code\"]</td>\n",
       "      <td>final</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[\"survey\"]</td>\n",
       "      <td>[\"TESTS ORDERED\"]</td>\n",
       "      <td>final</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[\"survey\"]</td>\n",
       "      <td>[\"TESTS ORDERED\"]</td>\n",
       "      <td>final</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[\"survey\"]</td>\n",
       "      <td>[\"TUBERCULOSIS PROPHYLAXIS PLAN\"]</td>\n",
       "      <td>final</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     category                                       code_display status\n",
       "0  [\"survey\"]  [\"CURRENT ANTIRETROVIRAL DRUGS USED FOR TREATM...  final\n",
       "1  [\"survey\"]                                     [\"LOINC Code\"]  final\n",
       "2  [\"survey\"]                                  [\"TESTS ORDERED\"]  final\n",
       "3  [\"survey\"]                                  [\"TESTS ORDERED\"]  final\n",
       "4  [\"survey\"]                  [\"TUBERCULOSIS PROPHYLAXIS PLAN\"]  final"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runner.to_dataframe(\n",
    "    obs.select(\n",
    "        {\n",
    "            \"category\": obs.category.coding.code,\n",
    "            \"code_display\": obs.code.coding.display,\n",
    "            \"status\": obs.status,\n",
    "        }\n",
    "    ),\n",
    "    limit=5,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course just a sample of codes isn't too useful -- we really want a summary of what codes exist in a field and how many there are. Fortunately, the Spark runner supports a summarize_codes method that accepts a view and a field name and does exactly that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>system</th>\n",
       "      <th>code</th>\n",
       "      <th>display</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://terminology.hl7.org/CodeSystem/observat...</td>\n",
       "      <td>survey</td>\n",
       "      <td>survey</td>\n",
       "      <td>675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://terminology.hl7.org/CodeSystem/observat...</td>\n",
       "      <td>exam</td>\n",
       "      <td>exam</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              system    code display  count\n",
       "0  http://terminology.hl7.org/CodeSystem/observat...  survey  survey    675\n",
       "1  http://terminology.hl7.org/CodeSystem/observat...    exam    exam     13"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runner.summarize_codes(obs, obs.category)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Views\n",
    "\n",
    "FHIR Data is complicated, but there is usually a flat, tabular form of it that can satisfy a given use case and data set.\n",
    "\n",
    "For example, imagine we need a simple table of patients with their current address. This isn't trivial to query since the address is a nested repeated field. Fortunately we can build a FHIRPath expression to find the current address and create a flattened view using that.\n",
    "\n",
    "(This can vary by dataset, but in this case we determine the current address by finding the first address that does not have a period attached to it.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>birthdate</th>\n",
       "      <th>street</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>zip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4765</td>\n",
       "      <td>male</td>\n",
       "      <td>1984-09-09</td>\n",
       "      <td>[\"754 Feil Tunnel Unit 36\"]</td>\n",
       "      <td>[\"Springfield\"]</td>\n",
       "      <td>[\"MA\"]</td>\n",
       "      <td>[\"01119\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4767</td>\n",
       "      <td>female</td>\n",
       "      <td>1999-04-26</td>\n",
       "      <td>[\"766 King Landing Suite 14\"]</td>\n",
       "      <td>[\"Spencer\"]</td>\n",
       "      <td>[\"MA\"]</td>\n",
       "      <td>[\"01562\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4768</td>\n",
       "      <td>female</td>\n",
       "      <td>1999-02-12</td>\n",
       "      <td>[\"508 Auer Lodge\"]</td>\n",
       "      <td>[\"Wilbraham\"]</td>\n",
       "      <td>[\"MA\"]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4770</td>\n",
       "      <td>male</td>\n",
       "      <td>1999-07-01</td>\n",
       "      <td>[\"230 Olson Fort Suite 50\"]</td>\n",
       "      <td>[\"Dennis\"]</td>\n",
       "      <td>[\"MA\"]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4776</td>\n",
       "      <td>female</td>\n",
       "      <td>1993-07-31</td>\n",
       "      <td>[\"612 Kuhlman Skyway Apt 45\"]</td>\n",
       "      <td>[\"Amherst\"]</td>\n",
       "      <td>[\"MA\"]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  gender  birthdate                         street             city  \\\n",
       "0  4765    male 1984-09-09    [\"754 Feil Tunnel Unit 36\"]  [\"Springfield\"]   \n",
       "1  4767  female 1999-04-26  [\"766 King Landing Suite 14\"]      [\"Spencer\"]   \n",
       "2  4768  female 1999-02-12             [\"508 Auer Lodge\"]    [\"Wilbraham\"]   \n",
       "3  4770    male 1999-07-01    [\"230 Olson Fort Suite 50\"]       [\"Dennis\"]   \n",
       "4  4776  female 1993-07-31  [\"612 Kuhlman Skyway Apt 45\"]      [\"Amherst\"]   \n",
       "\n",
       "    state        zip  \n",
       "0  [\"MA\"]  [\"01119\"]  \n",
       "1  [\"MA\"]  [\"01562\"]  \n",
       "2  [\"MA\"]         []  \n",
       "3  [\"MA\"]         []  \n",
       "4  [\"MA\"]         []  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For this dataset we interpret the current address as one where period is empty.\n",
    "\n",
    "current = pats.address.where(pats.address.period.empty())\n",
    "\n",
    "simple_pats = pats.select(\n",
    "    {\n",
    "        \"id\": pats.id,\n",
    "        \"gender\": pats.gender,\n",
    "        \"birthdate\": pats.birthDate,\n",
    "        \"street\": current.line,\n",
    "        \"city\": current.city,\n",
    "        \"state\": current.state,\n",
    "        \"zip\": current.postalCode,\n",
    "    }\n",
    ")\n",
    "\n",
    "runner.to_dataframe(simple_pats, limit=5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's nice, but suppose we want to create it as an actual Spark view -- basically a virtual table that can be easily used by any application that uses Spark. We can simply turn that definition into a Spark view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner.create_database_view(simple_pats, \"patients\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>birthdate</th>\n",
       "      <th>street</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>zip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4765</td>\n",
       "      <td>male</td>\n",
       "      <td>1984-09-09</td>\n",
       "      <td>[\"754 Feil Tunnel Unit 36\"]</td>\n",
       "      <td>[\"Springfield\"]</td>\n",
       "      <td>[\"MA\"]</td>\n",
       "      <td>[\"01119\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4767</td>\n",
       "      <td>female</td>\n",
       "      <td>1999-04-26</td>\n",
       "      <td>[\"766 King Landing Suite 14\"]</td>\n",
       "      <td>[\"Spencer\"]</td>\n",
       "      <td>[\"MA\"]</td>\n",
       "      <td>[\"01562\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4768</td>\n",
       "      <td>female</td>\n",
       "      <td>1999-02-12</td>\n",
       "      <td>[\"508 Auer Lodge\"]</td>\n",
       "      <td>[\"Wilbraham\"]</td>\n",
       "      <td>[\"MA\"]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4770</td>\n",
       "      <td>male</td>\n",
       "      <td>1999-07-01</td>\n",
       "      <td>[\"230 Olson Fort Suite 50\"]</td>\n",
       "      <td>[\"Dennis\"]</td>\n",
       "      <td>[\"MA\"]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4776</td>\n",
       "      <td>female</td>\n",
       "      <td>1993-07-31</td>\n",
       "      <td>[\"612 Kuhlman Skyway Apt 45\"]</td>\n",
       "      <td>[\"Amherst\"]</td>\n",
       "      <td>[\"MA\"]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  gender  birthdate                         street             city  \\\n",
       "0  4765    male 1984-09-09    [\"754 Feil Tunnel Unit 36\"]  [\"Springfield\"]   \n",
       "1  4767  female 1999-04-26  [\"766 King Landing Suite 14\"]      [\"Spencer\"]   \n",
       "2  4768  female 1999-02-12             [\"508 Auer Lodge\"]    [\"Wilbraham\"]   \n",
       "3  4770    male 1999-07-01    [\"230 Olson Fort Suite 50\"]       [\"Dennis\"]   \n",
       "4  4776  female 1993-07-31  [\"612 Kuhlman Skyway Apt 45\"]      [\"Amherst\"]   \n",
       "\n",
       "    state        zip  \n",
       "0  [\"MA\"]  [\"01119\"]  \n",
       "1  [\"MA\"]  [\"01562\"]  \n",
       "2  [\"MA\"]         []  \n",
       "3  [\"MA\"]         []  \n",
       "4  [\"MA\"]         []  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas.read_sql_query(\n",
    "    sql=\"SELECT * FROM statin_analysis_example.patients LIMIT 5\",\n",
    "    con=query_engine,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a nice, flattened patients table that meets the needs of our system and data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
